{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Knowledge_Graph_NLTK.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Resource\n",
        "1. [NLTK Chunking, i.e. Grouping](https://youtu.be/X2vAabgKiuM?t=2165)\n",
        "2. [NLTK Tokenize]()\n",
        "3. []()"
      ],
      "metadata": {
        "id": "MljssTCMtTRp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "import bs4\n",
        "import requests\n",
        "import spacy\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "from spacy import displacy\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "from spacy.matcher import Matcher \n",
        "from spacy.tokens import Span \n",
        "import networkx as nx\n",
        "from tqdm import tqdm\n"
      ],
      "metadata": {
        "id": "wg86IVySqw6_",
        "outputId": "dc6d4fd0-580c-4092-ebfd-4c828ade839a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "faq = pd.read_csv('/content/faq.csv')\n",
        "faq.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z47UZY7NrRmv",
        "outputId": "e66dedea-695c-46bf-a598-ffcd1aa776b2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(90, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "faq.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "Xyb8i-Myrd1R",
        "outputId": "d698d093-7be0-4bf9-ed08-b555a372344e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            question  \\\n",
              "0            What if I need to know my correct CGPA?   \n",
              "1  I have cleared my backlog but the result sheet...   \n",
              "2  I have cleared my backlog, but the result on E...   \n",
              "3  What do I do if I have not received my grade c...   \n",
              "4  My name/Father's Name/Mother's name is incorre...   \n",
              "\n",
              "                                              answer  \\\n",
              "0  CGPA is seen on the grade card. The CGPA count...   \n",
              "1   GPA and CGPA are not mentioned on backlog gra...   \n",
              "2   Grade card shows first attempt GPA and CGPA o...   \n",
              "3  Grade cards should be collected from the stude...   \n",
              "4   Name correction on grade cards/PDC needs to b...   \n",
              "\n",
              "                         category  \n",
              "0                      grade card  \n",
              "1                      grade card  \n",
              "2                      grade card  \n",
              "3                      grade card  \n",
              "4  Corrections on grade card /PDC  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a75258c6-e9e5-4b01-b6c9-a23a5d22eaad\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What if I need to know my correct CGPA?</td>\n",
              "      <td>CGPA is seen on the grade card. The CGPA count...</td>\n",
              "      <td>grade card</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I have cleared my backlog but the result sheet...</td>\n",
              "      <td>GPA and CGPA are not mentioned on backlog gra...</td>\n",
              "      <td>grade card</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I have cleared my backlog, but the result on E...</td>\n",
              "      <td>Grade card shows first attempt GPA and CGPA o...</td>\n",
              "      <td>grade card</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What do I do if I have not received my grade c...</td>\n",
              "      <td>Grade cards should be collected from the stude...</td>\n",
              "      <td>grade card</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>My name/Father's Name/Mother's name is incorre...</td>\n",
              "      <td>Name correction on grade cards/PDC needs to b...</td>\n",
              "      <td>Corrections on grade card /PDC</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a75258c6-e9e5-4b01-b6c9-a23a5d22eaad')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a75258c6-e9e5-4b01-b6c9-a23a5d22eaad button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a75258c6-e9e5-4b01-b6c9-a23a5d22eaad');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_a = faq.answer[1]\n",
        "text_q = faq.question[1]"
      ],
      "metadata": {
        "id": "evXH8Amyzn7R"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from nltk import word_tokenize\n",
        "\n",
        "sentences = sent_tokenize(text_q)\n",
        "stemmer = PorterStemmer()\n",
        "new_sentence = []\n",
        "for i in range(len(sentences)):\n",
        "    words = word_tokenize(sentences[i])\n",
        "    words = [stemmer.stem(word) for word in words]\n",
        "    new_sentence.append(' '.join(words))\n",
        "print(new_sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUXA_TJT84p7",
        "outputId": "31eba3ae-15c6-499d-8936-754e6aef3680"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['I have clear my backlog but the result sheet doe not show gpa and cgpa .', 'whi ?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m -q spacy download en_core_web_lg\n",
        "!python -m -q spacy download en_core_web_sm\n",
        "!python -m -q spacy download en"
      ],
      "metadata": {
        "id": "dAw997q9vfHH",
        "outputId": "f0f0170d-c35b-4d92-c721-45fb1a585f47",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en_core_web_lg==2.2.5\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-2.2.5/en_core_web_lg-2.2.5.tar.gz (827.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 827.9 MB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_lg==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.21.6)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (2.0.6)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (3.0.6)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (57.4.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.7)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (4.64.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (0.9.1)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (4.2.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.0.4)\n",
            "Building wheels for collected packages: en-core-web-lg\n",
            "  Building wheel for en-core-web-lg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for en-core-web-lg: filename=en_core_web_lg-2.2.5-py3-none-any.whl size=829180942 sha256=b5348d9269f52fa9887eda99d81e7bd7ac6260b0ccc81dec01b5bec960e6bd9e\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-p4849i4g/wheels/11/95/ba/2c36cc368c0bd339b44a791c2c1881a1fb714b78c29a4cb8f5\n",
            "Successfully built en-core-web-lg\n",
            "Installing collected packages: en-core-web-lg\n",
            "Successfully installed en-core-web-lg-2.2.5\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_lg')\n",
            "Collecting en_core_web_sm==2.2.5\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz (12.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.0 MB 8.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.64.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.6)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.9.1)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.7)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.21.6)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (57.4.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (4.2.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Keyword Extraction \n",
        "[source](https://towardsdatascience.com/keyword-extraction-process-in-python-with-natural-language-processing-nlp-d769a9069d5c)\n",
        "1. Using NLTK\n",
        "2. Yakes "
      ],
      "metadata": {
        "id": "Gr8AeCuKyKuj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy \n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(text)\n",
        "print(doc)\n",
        "print(doc.ents)"
      ],
      "metadata": {
        "id": "uxqxV3zmvObu",
        "outputId": "515ea5c2-66ea-474c-82e7-1519f7b21c09",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " GPA and CGPA are not mentioned on backlog grade cards. GPA, CGPA will be highlighted on regular trimester grade card only.\n",
            "(GPA, CGPA, GPA, CGPA)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q git+https://github.com/LIAAD/yake\n",
        "# Github: https://github.com/LIAAD/yake\n",
        "\n",
        "import yake\n",
        "kw_extract = yake.KeywordExtractor()\n",
        "language = 'en'\n",
        "max_ngram_size = 3\n",
        "deduplication_threshold = 0.9\n",
        "numOfKeywords = 20\n",
        "custom_kw_extractor = yake.KeywordExtractor(lan=language, n=max_ngram_size, dedupLim=deduplication_threshold, top=numOfKeywords, features=None)\n",
        "keywords = custom_kw_extractor.extract_keywords(text_q)\n",
        "print(text_q)\n",
        "for kw in keywords:\n",
        "  print(kw)"
      ],
      "metadata": {
        "id": "aPWlGQPKyfje",
        "outputId": "7343417d-6dd3-4154-ac0f-7d912301750a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I have cleared my backlog but the result sheet does not show GPA and CGPA. Why?\n",
            "('GPA and CGPA', 0.01560470695632768)\n",
            "('show GPA', 0.0605689221549672)\n",
            "('CGPA', 0.09705179139403544)\n",
            "('cleared my backlog', 0.1495930091794576)\n",
            "('result sheet', 0.1495930091794576)\n",
            "('GPA', 0.15831692877998726)\n",
            "('cleared', 0.36073110501666333)\n",
            "('backlog', 0.36073110501666333)\n",
            "('result', 0.36073110501666333)\n",
            "('sheet', 0.36073110501666333)\n",
            "('show', 0.36073110501666333)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import word_tokenize, pos_tag\n",
        "new_tok = pos_tag(word_tokenize(text_q))\n",
        "new_tok"
      ],
      "metadata": {
        "id": "jlb7o6KH1jbG",
        "outputId": "4aa1203b-276c-4b70-d738-acb2deab4c60",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('I', 'PRP'),\n",
              " ('have', 'VBP'),\n",
              " ('cleared', 'VBN'),\n",
              " ('my', 'PRP$'),\n",
              " ('backlog', 'NN'),\n",
              " ('but', 'CC'),\n",
              " ('the', 'DT'),\n",
              " ('result', 'NN'),\n",
              " ('sheet', 'NN'),\n",
              " ('does', 'VBZ'),\n",
              " ('not', 'RB'),\n",
              " ('show', 'VB'),\n",
              " ('GPA', 'NNP'),\n",
              " ('and', 'CC'),\n",
              " ('CGPA', 'NNP'),\n",
              " ('.', '.'),\n",
              " ('Why', 'WRB'),\n",
              " ('?', '.')]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "grammar_np = r'NP: {<DT>?<JJ>*<NN>}'"
      ],
      "metadata": {
        "id": "8w-rqvhA26fA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chunk_parser = nltk.RegexpParser(grammar_np)\n",
        "chunk_result = chunk_parser.parse(new_tok)\n",
        "chunk_result"
      ],
      "metadata": {
        "id": "txOffNcD3EbT",
        "outputId": "b6a34f8b-717f-4e80-e6e2-7654fd832322",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    336\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 338\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/tree/tree.py\u001b[0m in \u001b[0;36m_repr_svg_\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_repr_svg_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 783\u001b[0;31m         \u001b[0;32mfrom\u001b[0m \u001b[0msvgling\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdraw_tree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    784\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdraw_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_repr_svg_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'svgling'"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Tree('S', [('I', 'PRP'), ('have', 'VBP'), ('cleared', 'VBN'), ('my', 'PRP$'), Tree('NP', [('backlog', 'NN')]), ('but', 'CC'), Tree('NP', [('the', 'DT'), ('result', 'NN')]), Tree('NP', [('sheet', 'NN')]), ('does', 'VBZ'), ('not', 'RB'), ('show', 'VB'), ('GPA', 'NNP'), ('and', 'CC'), ('CGPA', 'NNP'), ('.', '.'), ('Why', 'WRB'), ('?', '.')])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(faq['question'][3])\n",
        "for tok in doc: \n",
        "  print(tok.text, '---', tok.dep_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CMJ1kXPnrgZ1",
        "outputId": "08e4492f-e579-4107-e0c9-d2ab4f441898"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What --- dobj\n",
            "do --- aux\n",
            "I --- nsubj\n",
            "do --- ROOT\n",
            "if --- mark\n",
            "I --- nsubj\n",
            "have --- aux\n",
            "not --- neg\n",
            "received --- advcl\n",
            "my --- poss\n",
            "grade --- compound\n",
            "card --- dobj\n",
            "? --- punct\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "t = word_tokenize(faq.question[1])    # all words\n",
        "t_sw = [word for word in t if not word in stopwords.words()]\n",
        "\n",
        "pun = ['.', ',', '?']\n",
        "t = [word for word in t_sw if word != pun]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Lp7DaELJ3CJ",
        "outputId": "e37906df-7214-4a53-c693-844d19f426ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(t)\n",
        "# print(t_sw)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fz7uFqEdOOFD",
        "outputId": "ab262d08-ae2d-41d3-9d59-4419878b3573"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['I', 'cleared', 'backlog', 'result', 'sheet', 'show', 'GPA', 'CGPA', '.', 'Why', '?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(t)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fkuAkoPfLTHI",
        "outputId": "fb87e1f8-9424-45c4-fe70-cd2d63ee3c3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(t)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7r_DaJBNMGCu",
        "outputId": "b9fb9c64-c456-4f6f-f313-2fdcae47ac1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['I', 'have', 'cleared', 'my', 'backlog', 'but', 'the', 'result', 'sheet', 'does', 'not', 'show', 'GPA', 'and', 'CGPA', '.', 'Why']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pun = [',', '.', '?']\n",
        "# for i in pun:\n",
        "t.remove('?')\n",
        "len(t)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3RABavyKufc",
        "outputId": "586fefe2-5c73-4593-9df1-899cec54c1c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "st = []\n",
        "for tok in nlp(faq.question[1]):\n",
        "  if tok.dep_ != 'punct':\n",
        "    st.append(tok)"
      ],
      "metadata": {
        "id": "DNK4IrOMMWFC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "st"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wUPwVUh3NLOU",
        "outputId": "d7fef19f-a39b-4ae7-a4b2-5b7946d2f38e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[I,\n",
              " have,\n",
              " cleared,\n",
              " my,\n",
              " backlog,\n",
              " but,\n",
              " the,\n",
              " result,\n",
              " sheet,\n",
              " does,\n",
              " not,\n",
              " show,\n",
              " GPA,\n",
              " and,\n",
              " CGPA,\n",
              " Why]"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_entities(sent):\n",
        "  ## chunk 1\n",
        "  ent1 = \"\"\n",
        "  ent2 = \"\"\n",
        "\n",
        "  prv_tok_dep = \"\"    # dependency tag of previous token in the sentence\n",
        "  prv_tok_text = \"\"   # previous token in the sentence\n",
        "\n",
        "  prefix = \"\"\n",
        "  modifier = \"\"\n",
        "  \n",
        "  for tok in nlp(sent):\n",
        "    # chunk 2\n",
        "    # if token is a punctuation mark then move on to the next token\n",
        "    if tok.dep_ != \"punct\":\n",
        "      # check: token is a compound word or not\n",
        "      if tok.dep_ == \"compound\":\n",
        "        prefix = tok.text\n",
        "        # if the previous word was also a 'compound' then add the current word to it\n",
        "        if prv_tok_dep == \"compound\":\n",
        "          prefix = prv_tok_text + \" \"+ tok.text\n",
        "      \n",
        "      # check: token is a modifier or not\n",
        "      if tok.dep_.endswith(\"mod\") == True:\n",
        "        modifier = tok.text\n",
        "        # if the previous word was also a 'compound' then add the current word to it\n",
        "        if prv_tok_dep == \"compound\":\n",
        "          modifier = prv_tok_text + \" \"+ tok.text\n",
        "      \n",
        "      ## chunk 3\n",
        "      if tok.dep_.find(\"subj\") == True:\n",
        "        ent1 = modifier +\" \"+ prefix + \" \"+ tok.text\n",
        "        prefix = \"\"\n",
        "        modifier = \"\"\n",
        "        prv_tok_dep = \"\"\n",
        "        prv_tok_text = \"\"      \n",
        "\n",
        "      ## chunk 4\n",
        "      if tok.dep_.find(\"obj\") == True:\n",
        "        ent2 = modifier +\" \"+ prefix +\" \"+ tok.text\n",
        "        \n",
        "      ## chunk 5  \n",
        "      # update variables\n",
        "      prv_tok_dep = tok.dep_\n",
        "      prv_tok_text = tok.text\n",
        "\n",
        "  return [ent1.strip(), ent2.strip()]"
      ],
      "metadata": {
        "id": "RS3-HpQKr0BJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Chunk 1**\n",
        "\n",
        "Defined a few empty variables in this chunk. prv_tok_dep and prv_tok_text will hold the dependency tag of the previous word in the sentence and that previous word itself, respectively. prefix and modifier will hold the text that is associated with the subject or the object.\n",
        "\n",
        "**Chunk 2**\n",
        "\n",
        "Next, we will loop through the tokens in the sentence. We will first check if the token is a punctuation mark or not. If yes, then we will ignore it and move on to the next token. If the token is a part of a compound word (dependency tag = “compound”), we will keep it in the prefix variable. A compound word is a combination of multiple words linked to form a word with a new meaning (example – “Football Stadium”, “animal lover”).\n",
        "\n",
        "As and when we come across a subject or an object in the sentence, we will add this prefix to it. We will do the same thing with the modifier words, such as “nice shirt”, “big house”, etc.\n",
        "\n",
        "**Chunk 3**\n",
        "\n",
        "Here, if the token is the subject, then it will be captured as the first entity in the ent1 variable. Variables such as prefix, modifier, prv_tok_dep, and prv_tok_text will be reset.\n",
        "\n",
        "**Chunk 4**\n",
        "\n",
        "Here, if the token is the object, then it will be captured as the second entity in the ent2 variable. Variables such as prefix, modifier, prv_tok_dep, and prv_tok_text will again be reset.\n",
        "\n",
        "**Chunk 5**\n",
        "\n",
        "Once we have captured the subject and the object in the sentence, we will update the previous token and its dependency tag.\n",
        "\n",
        "Let’s test this function on a sentence:"
      ],
      "metadata": {
        "id": "0lXaK_ARxTjo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in faq.question.head(10):\n",
        "  print(i)\n",
        "  print(get_entities(i))\n",
        "  print('---')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40FcP32p4SLI",
        "outputId": "9042252a-db99-45ec-ebc7-4020c1412b3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What if I need to know my correct CGPA?\n",
            "['I', 'correct  CGPA']\n",
            "---\n",
            "I have cleared my backlog but the result sheet does not show GPA and CGPA. Why?\n",
            "['result sheet', 'GPA']\n",
            "---\n",
            "I have cleared my backlog, but the result on ERP is not updated .It still shows earlier CGPA.As a result, it is affecting my CGPA of next trimesters also. How do I get it corrected?\n",
            "['it', 'next  trimesters']\n",
            "---\n",
            "What do I do if I have not received my grade card?\n",
            "['I', 'grade card']\n",
            "---\n",
            "My name/Father's Name/Mother's name is incorrect on grade card. How do I get it corrected?\n",
            "['it', 'grade card']\n",
            "---\n",
            "How can I get a new copy of corrected grade cards?\n",
            "['How  I', 'corrected grade cards']\n",
            "---\n",
            "From where should I collect the corrected grade cards/PDC?\n",
            "['where  I', 'grade cards grade PDC']\n",
            "---\n",
            "In how many days will I get the corrected grade cards?\n",
            "['days  I', 'corrected grade cards']\n",
            "---\n",
            "Do I need to submit an Exam form for the end term exam?\n",
            "['I', 'end term exam']\n",
            "---\n",
            "I have an internal backlog, do I need to submit an exam form?\n",
            "['internal  I', 'exam form']\n",
            "---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "entity_pairs = []\n",
        "\n",
        "for i in faq.question.head(10):\n",
        "  entity_pairs.append(get_entities(i))\n"
      ],
      "metadata": {
        "id": "hLMt6zvI4UU-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "entity_pairs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0T7b0e6o7lIY",
        "outputId": "7ab3c905-ce6a-44f0-dbe2-9cb8775b0389"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['I', 'correct  CGPA'],\n",
              " ['result sheet', 'GPA'],\n",
              " ['it', 'next  trimesters'],\n",
              " ['I', 'grade card'],\n",
              " ['it', 'grade card'],\n",
              " ['How  I', 'corrected grade cards'],\n",
              " ['where  I', 'grade cards grade PDC'],\n",
              " ['days  I', 'corrected grade cards'],\n",
              " ['I', 'end term exam'],\n",
              " ['internal  I', 'exam form']]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_relation(sent):\n",
        "\n",
        "  doc = nlp(sent)\n",
        "\n",
        "  # Matcher class object \n",
        "  matcher = Matcher(nlp.vocab)\n",
        "\n",
        "  #define the pattern \n",
        "  pattern = [{'DEP':'ROOT'}, \n",
        "            {'DEP':'prep','OP':\"?\"},\n",
        "            {'DEP':'agent','OP':\"?\"},  \n",
        "            {'POS':'ADJ','OP':\"?\"}] \n",
        "\n",
        "  matcher.add(\"matching_1\", None, pattern) \n",
        "\n",
        "  matches = matcher(doc)\n",
        "  k = len(matches) - 1\n",
        "\n",
        "  span = doc[matches[k][1]:matches[k][2]] \n",
        "\n",
        "  return(span.text)"
      ],
      "metadata": {
        "id": "h931nzvjFQ3L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in faq.question.head(10):\n",
        "  print(get_relation(i))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cq0PP-U-ISdD",
        "outputId": "d9ba8fb6-a614-4c2e-8275-5c2ddfc32dab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What\n",
            "Why\n",
            "get\n",
            "do\n",
            "get\n",
            "get\n",
            "collect\n",
            "get\n",
            "need\n",
            "need\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "relations = [get_relation(i) for i in tqdm(faq.question.head(10))]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qT_igzDYIdUY",
        "outputId": "0622344d-514a-40d7-b5b4-f17a0e63993d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 59.79it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.Series(relations).value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DIcEPyYuIpaT",
        "outputId": "51b74d6e-e57e-4780-db1a-b0194247d125"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "get        4\n",
              "need       2\n",
              "What       1\n",
              "Why        1\n",
              "do         1\n",
              "collect    1\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "e_OMyYhvIuTK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}